{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Basic Machine Learning Algorithms on Ames Housing Dataset (Regression Task)\n",
    "\n",
    "This notebook implements Linear Regression on the Ames Housing Dataset. The dataset has been provided by Kaggle. https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from LinearRegression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial train data size (1460, 81)\n",
      "updated training data size (1460, 329)\n",
      "(1460, 328)\n",
      "(1460, 1)\n",
      "(1460, 328)\n",
      "(1460, 1)\n",
      "[    0.   100.   200.   300.   400.   500.   600.   700.   800.   900.\n",
      "  1000.]\n",
      "[ 1.39712683  0.74986931  0.61880285  0.5258194   0.46182226  0.41914873\n",
      "  0.39149702  0.37396735  0.36299977  0.35616317  0.35187533]\n",
      "Learning rate = 1e-09\n",
      "[    0.   100.   200.   300.   400.   500.   600.   700.   800.   900.\n",
      "  1000.]\n",
      "[ 1.39712683  0.41826198  0.35172074  0.34455182  0.3424598   0.34098679\n",
      "  0.33975176  0.3386846   0.33774768  0.33691335  0.33616053]\n",
      "Learning rate = 5e-09\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def plot_curve(Xlist, Ylist, title, xlabel, ylabel, plotlabels):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    cnt = 0\n",
    "    for X in Xlist:\n",
    "        print(X)\n",
    "        Y = Ylist[cnt]\n",
    "        print(Y)\n",
    "        label = plotlabels[cnt]\n",
    "        print(label)\n",
    "        plt.plot(X, Y, 'o-', label=label)\n",
    "        cnt += 1\n",
    "    #plt.show()\n",
    "\n",
    "def load_dataset():\n",
    "    train_initial = pd.read_csv('datasets/train.csv')\n",
    "    test_initial = pd.read_csv('datasets/test.csv')\n",
    "    return train_initial, test_initial\n",
    "\n",
    "train_initial, test_initial = load_dataset()\n",
    "print(\"initial train data size\", train_initial.shape)\n",
    "\n",
    "#print(train_initial.columns.values[train_initial.isnull().sum() > 0])\n",
    "#print(test_initial.columns.values[test_initial.isnull().sum() > 0])\n",
    "#print(train_initial['GarageYrBlt'].isnull().sum())\n",
    "#print(train_initial.mode()['MasVnrArea'])\n",
    "#print(train_initial.dtypes)\n",
    "\n",
    "train_2 = train_initial.copy()\n",
    "\n",
    "# ignore Id; ignore MasVnrArea and GarageYrBlt too for now as no easy way of handling missing values\n",
    "train_2 = train_2.drop(['Id', 'MasVnrArea', 'GarageYrBlt'], axis=1)\n",
    "\n",
    "# transform year variables to be, 'years since 2018'\n",
    "train_2[['YearBuilt', 'YearRemodAdd', 'YrSold']] = 2018 - train_2[['YearBuilt', 'YearRemodAdd', 'YrSold']]\n",
    "\n",
    "numeric_features = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    " 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    " 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    " 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    " 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    " 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold', 'SalePrice']\n",
    "\n",
    "# get non-numeric columns\n",
    "non_numeric_columns = np.setdiff1d(train_2.columns.values,numeric_features)\n",
    "\n",
    "# create dummy variables for categorical variables\n",
    "# TODO: ideally would want to create these based on a list of possible feature values,\n",
    "# otherwise will have to combine with test data and then create dummy variables \n",
    "# as some feature values might be present in one set but not the other sample\n",
    "train_2 = pd.get_dummies(train_2, columns=non_numeric_columns, drop_first=True, dummy_na=True)\n",
    "print(\"updated training data size\", train_2.shape)\n",
    "\n",
    "# interaction variable for MiscVal based on type of MiscFeature\n",
    "miscfeatures = [col for col in train_2.columns.values if col.startswith('MiscFeature')]\n",
    "\n",
    "train_2[miscfeatures] = train_2[miscfeatures].multiply(train_2['MiscVal'],axis=\"index\")\n",
    "\n",
    "#print(train_2.head(5))\n",
    "\n",
    "#print(train_2[train_2.columns[-15:]].head())\n",
    "#print(train_2.dtypes)\n",
    "\n",
    "learning_rate = [0.000000001, 0.000000005]\n",
    "max_iter = 1000\n",
    "iteration_threshold = 100\n",
    "\n",
    "#cost_by_lr = np.array([])\n",
    "#iterations = np.array([])\n",
    "#plotlabels = np.array([])\n",
    "\n",
    "cost_by_lr = np.empty((0,math.floor(max_iter/iteration_threshold)+1))\n",
    "iterations = np.empty((0,math.floor(max_iter/iteration_threshold)+1))\n",
    "plotlabels = []\n",
    "\n",
    "for lr in learning_rate:\n",
    "    estimator_linReg = LinearRegression(learning_rate=lr, reg_strength=0, regularization=\"Ridge\", \n",
    "                                    max_iter=max_iter, gd_threshold=None, iteration_threshold=iteration_threshold)\n",
    "\n",
    "\n",
    "    train_2 = train_2.fillna(train_2.mean())\n",
    "\n",
    "    #print(train_2.columns.values[train_2.isnull().sum() > 0])\n",
    "\n",
    "    train_X = train_2.drop(['SalePrice'], axis=1).values\n",
    "    #print(train_X[:10,])/9\n",
    "    #train_X = train_X[0:10,:2]\n",
    "    #print(train_X)\n",
    "    print(train_X.shape)\n",
    "    train_y = train_2[['SalePrice']].values\n",
    "    #train_y = train_y[0:10,]\n",
    "    train_y = train_y / 100000\n",
    "    print(train_y.shape)\n",
    "\n",
    "    #print(train_y)\n",
    "\n",
    "    estimator_linReg.fit(train_X, train_y)\n",
    "    estimator_linReg.final_cost\n",
    "    \n",
    "    #print(estimator_linReg.cost_by_iteration)\n",
    "\n",
    "    cost_by_lr = np.vstack((cost_by_lr, estimator_linReg.cost_by_iteration))\n",
    "    \n",
    "    #print(cost_by_lr)\n",
    "    iterations = np.vstack((iterations, estimator_linReg.iterations))\n",
    "    plotlabels.append(\"Learning rate = \"+str(lr))\n",
    "    #iterations = np.append(iterations, estimator_linReg.iterations)\n",
    "    #plotlabels = np.append(plotlabels, \"Learning rate = \"+str(lr))\n",
    "\n",
    "#print(cost_by_iter)\n",
    "#print(iterations)\n",
    "\n",
    "plot_curve(Ylist=cost_by_lr, Xlist=iterations, title=\"Curve for cost v/s iteration by learning rate\", \n",
    "           xlabel=\"Number of iterations\", ylabel=\"Cost\", plotlabels=plotlabels)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
